# -*- coding: utf-8 -*-
"""AJS - Project 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FSvftTOR_a6-tAW-IDQ4Hct_xdQsFAPD
"""

# Import required Python package
!pip install snscrape
!pip install pyvis
!pip install pandas

# Install Node.js (because tweet-harvest built using Node.js)
!sudo apt-get update
!sudo apt-get install -y ca-certificates curl gnupg
!sudo mkdir -p /etc/apt/keyrings
!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg

!NODE_MAJOR=20 && echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | sudo tee /etc/apt/sources.list.d/nodesource.list

!sudo apt-get update
!sudo apt-get install nodejs -y

!node -v

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from networkx.algorithms.community import girvan_newman
from pyvis.network import Network
from IPython.core.display import display, HTML

# Crawl Data
# File to store the tweet harvest
filename = 'techbros.csv'

search_keyword = 'techbros since:2024-01-01'
limit = 1000

# Token can be found in your cookie as auth_token when you've logged in to Twitter.
!npx --yes tweet-harvest@latest -o "{filename}" -s "{search_keyword}" -l {limit} --token "240ee7b2cd1eb84d848b21e3ecf47327e07ff712"

import pandas as pd

filename = 'techbros.csv'

# Specify the path to your CSV file
file_path = f"{filename}"

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(file_path)

# Display the DataFrame
display(df.head(3))

num_tweets = len(df)
print(f"Jumlah tweet dalam dataframe adalah {num_tweets}.")

# Preprocess the data
df = df[['username', 'in_reply_to_screen_name']].dropna()
df.drop_duplicates(inplace=True)

# Display the DataFrame
display(df.head(3))

num_tweets = len(df)
print(f"Jumlah tweet dalam dataframe adalah {num_tweets}.")

# Create graph
G = nx.from_pandas_edgelist(df, 'username', 'in_reply_to_screen_name')

# Apply Girvan-Newman algorithm
def girvan_newman_communities(G):
    comp = girvan_newman(G)
    communities = tuple(sorted(c) for c in next(comp))
    return communities

communities = girvan_newman_communities(G)

# Visualize communities
pos = nx.spring_layout(G)
plt.figure(figsize=(12, 8))
colors = ['r', 'g', 'b', 'y', 'c', 'm', 'k']

for i, community in enumerate(communities):
    # nx.draw_networkx_nodes(G, pos, community, node_size=50, node_color=colors[i % len(colors)], label=f'Community {i + 1}')
    nx.draw_networkx_nodes(G, pos, community, node_size=25, node_color=colors[i % len(colors)])

nx.draw_networkx_edges(G, pos, alpha=0.5)
plt.title('Community Detection using Girvan-Newman Algorithm')
plt.legend()
plt.show()

# Print detected communities
for i, community in enumerate(communities):
    print(f"Community {i + 1}: {community}")